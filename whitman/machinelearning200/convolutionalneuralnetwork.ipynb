{"cells":[{"cell_type":"markdown","metadata":{"id":"m56CSPhtiAk8"},"source":["# Case Study 1: Building Image Classifier with CNN"]},{"cell_type":"markdown","source":["**Step 1: Building the Model**"],"metadata":{"id":"v14LETpQyjrT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJ96-AtsfzUZ"},"outputs":[],"source":["# Import libraries and load dataset\n","import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import load_img\n","from keras.utils import img_to_array\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/2022-23/S23/CS-200/Week 10/dogs_vs_cats/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLYGyZJwkpWG"},"outputs":[],"source":["# Initialize CNN\n","classifier = Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ab9WRjplPi5"},"outputs":[],"source":["# Convolution\n","classifier.add(Conv2D(filters = 32, kernel_size = 3, input_shape = [128, 128, 3], activation = 'relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4pYvlMXlxhn"},"outputs":[],"source":["# Pooling\n","classifier.add(MaxPooling2D(pool_size = 2, strides = 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kApAj718odIs"},"outputs":[],"source":["# Second convolution layer\n","classifier.add(Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JyqKejEodIt"},"outputs":[],"source":["# Second pooling layer\n","classifier.add(MaxPooling2D(pool_size = 2, strides = 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BX6nxppTqR62"},"outputs":[],"source":["# Flattening\n","classifier.add(Flatten())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Xk5r7m9qsMa"},"outputs":[],"source":["# Hidden layers\n","classifier.add(Dense(units = 128, activation = 'relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c1Xza2jrM1v"},"outputs":[],"source":["# Output layer\n","classifier.add(Dense(units = 1, activation = 'sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gf_RnR3urbv4"},"outputs":[],"source":["# Compilation\n","classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"markdown","source":["**Step 2: Image Augmentation and Evaluating the Model**"],"metadata":{"id":"XI17TxSEzVrg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"e4QLtNCmr94U"},"outputs":[],"source":["# TRAINING DATA\n","# Specify augmentation transformations\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   shear_range=0.2,\n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1681625440369,"user":{"displayName":"Samuel Boerner","userId":"02136363046085809473"},"user_tz":420},"id":"MZVh-vnXu_ll","outputId":"b97fdef2-8c07-4e07-b8ad-a150d6cb4ff1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 10000 images belonging to 2 classes.\n"]}],"source":["# Augment training data\n","train_generator = train_datagen.flow_from_directory('train',\n","                                                    target_size = (128, 128),\n","                                                    batch_size = 32,\n","                                                    class_mode = 'binary')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxRafgaFvNFp"},"outputs":[],"source":["# TESTING DATA\n","# Specify augmentation transformations\n","test_datagen = ImageDataGenerator(rescale = 1./255)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1681625440370,"user":{"displayName":"Samuel Boerner","userId":"02136363046085809473"},"user_tz":420},"id":"5u1zsUpIvUid","outputId":"a66829e2-e3f2-4f4b-eb96-e988bc319831"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 images belonging to 2 classes.\n"]}],"source":["# Augment testing data\n","test_generator = test_datagen.flow_from_directory('test',\n","                                                    target_size = (128, 128),\n","                                                    batch_size = 32,\n","                                                    class_mode = 'binary')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mlo2au4GvYqF","outputId":"dd39bc89-1d39-412d-a1dd-274c6a00ef05","executionInfo":{"status":"ok","timestamp":1681631078276,"user_tz":420,"elapsed":5634348,"user":{"displayName":"Samuel Boerner","userId":"02136363046085809473"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","100/100 [==============================] - ETA: 0s - loss: 0.7149 - accuracy: 0.5406"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 800 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 101s 995ms/step - loss: 0.7149 - accuracy: 0.5406 - val_loss: 0.6748 - val_accuracy: 0.5980\n","Epoch 2/50\n","100/100 [==============================] - 87s 871ms/step - loss: 0.6738 - accuracy: 0.6009\n","Epoch 3/50\n","100/100 [==============================] - 88s 881ms/step - loss: 0.6666 - accuracy: 0.6096\n","Epoch 4/50\n","100/100 [==============================] - 88s 874ms/step - loss: 0.6557 - accuracy: 0.6219\n","Epoch 5/50\n","100/100 [==============================] - 88s 875ms/step - loss: 0.6178 - accuracy: 0.6697\n","Epoch 6/50\n","100/100 [==============================] - 87s 872ms/step - loss: 0.6097 - accuracy: 0.6759\n","Epoch 7/50\n","100/100 [==============================] - 87s 867ms/step - loss: 0.5872 - accuracy: 0.6963\n","Epoch 8/50\n","100/100 [==============================] - 86s 856ms/step - loss: 0.5813 - accuracy: 0.6875\n","Epoch 9/50\n","100/100 [==============================] - 85s 845ms/step - loss: 0.5639 - accuracy: 0.7041\n","Epoch 10/50\n","100/100 [==============================] - 83s 827ms/step - loss: 0.5641 - accuracy: 0.7155\n","Epoch 11/50\n","100/100 [==============================] - 85s 856ms/step - loss: 0.5623 - accuracy: 0.7142\n","Epoch 12/50\n","100/100 [==============================] - 85s 849ms/step - loss: 0.5350 - accuracy: 0.7308\n","Epoch 13/50\n","100/100 [==============================] - 83s 831ms/step - loss: 0.5172 - accuracy: 0.7503\n","Epoch 14/50\n","100/100 [==============================] - 85s 851ms/step - loss: 0.4973 - accuracy: 0.7650\n","Epoch 15/50\n","100/100 [==============================] - 83s 833ms/step - loss: 0.5043 - accuracy: 0.7625\n","Epoch 16/50\n","100/100 [==============================] - 87s 865ms/step - loss: 0.4832 - accuracy: 0.7759\n","Epoch 17/50\n","100/100 [==============================] - 86s 863ms/step - loss: 0.4764 - accuracy: 0.7713\n","Epoch 18/50\n","100/100 [==============================] - 85s 850ms/step - loss: 0.4813 - accuracy: 0.7672\n","Epoch 19/50\n","100/100 [==============================] - 87s 857ms/step - loss: 0.4655 - accuracy: 0.7816\n","Epoch 20/50\n","100/100 [==============================] - 86s 863ms/step - loss: 0.4389 - accuracy: 0.7991\n","Epoch 21/50\n","100/100 [==============================] - 87s 865ms/step - loss: 0.4352 - accuracy: 0.7950\n","Epoch 22/50\n","100/100 [==============================] - 85s 847ms/step - loss: 0.4465 - accuracy: 0.7828\n","Epoch 23/50\n","100/100 [==============================] - 88s 877ms/step - loss: 0.4284 - accuracy: 0.8000\n","Epoch 24/50\n","100/100 [==============================] - 84s 843ms/step - loss: 0.4275 - accuracy: 0.7977\n","Epoch 25/50\n","100/100 [==============================] - 83s 828ms/step - loss: 0.4155 - accuracy: 0.8053\n","Epoch 26/50\n","100/100 [==============================] - 84s 835ms/step - loss: 0.4055 - accuracy: 0.8091\n","Epoch 27/50\n","100/100 [==============================] - 84s 843ms/step - loss: 0.4073 - accuracy: 0.8103\n","Epoch 28/50\n","100/100 [==============================] - 85s 841ms/step - loss: 0.3884 - accuracy: 0.8275\n","Epoch 29/50\n","100/100 [==============================] - 85s 844ms/step - loss: 0.3612 - accuracy: 0.8439\n","Epoch 30/50\n","100/100 [==============================] - 84s 844ms/step - loss: 0.3617 - accuracy: 0.8334\n","Epoch 31/50\n","100/100 [==============================] - 82s 819ms/step - loss: 0.3609 - accuracy: 0.8427\n","Epoch 32/50\n","100/100 [==============================] - 85s 837ms/step - loss: 0.3602 - accuracy: 0.8497\n","Epoch 33/50\n","100/100 [==============================] - 84s 844ms/step - loss: 0.3447 - accuracy: 0.8508\n","Epoch 34/50\n","100/100 [==============================] - 85s 846ms/step - loss: 0.3607 - accuracy: 0.8428\n","Epoch 35/50\n","100/100 [==============================] - 83s 828ms/step - loss: 0.3332 - accuracy: 0.8530\n","Epoch 36/50\n","100/100 [==============================] - 84s 840ms/step - loss: 0.3246 - accuracy: 0.8615\n","Epoch 37/50\n","100/100 [==============================] - 84s 841ms/step - loss: 0.3235 - accuracy: 0.8521\n","Epoch 38/50\n","100/100 [==============================] - 83s 830ms/step - loss: 0.3344 - accuracy: 0.8502\n","Epoch 39/50\n","100/100 [==============================] - 85s 850ms/step - loss: 0.3423 - accuracy: 0.8475\n","Epoch 40/50\n","100/100 [==============================] - 83s 831ms/step - loss: 0.3077 - accuracy: 0.8662\n","Epoch 41/50\n","100/100 [==============================] - 84s 827ms/step - loss: 0.3033 - accuracy: 0.8769\n","Epoch 42/50\n","100/100 [==============================] - 83s 827ms/step - loss: 0.2902 - accuracy: 0.8693\n","Epoch 43/50\n","100/100 [==============================] - 85s 845ms/step - loss: 0.2814 - accuracy: 0.8822\n","Epoch 44/50\n","100/100 [==============================] - 85s 850ms/step - loss: 0.2856 - accuracy: 0.8719\n","Epoch 45/50\n","100/100 [==============================] - 85s 849ms/step - loss: 0.2704 - accuracy: 0.8869\n","Epoch 46/50\n","100/100 [==============================] - 86s 847ms/step - loss: 0.2652 - accuracy: 0.8838\n","Epoch 47/50\n","100/100 [==============================] - 87s 865ms/step - loss: 0.2798 - accuracy: 0.8797\n","Epoch 48/50\n","100/100 [==============================] - 86s 861ms/step - loss: 0.2609 - accuracy: 0.8966\n","Epoch 49/50\n","100/100 [==============================] - 85s 845ms/step - loss: 0.2588 - accuracy: 0.8954\n","Epoch 50/50\n","100/100 [==============================] - 86s 856ms/step - loss: 0.2465 - accuracy: 0.8945\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f190050d9a0>"]},"metadata":{},"execution_count":15}],"source":["# Model fitting\n","classifier.fit(train_generator,\n","               steps_per_epoch = 100,\n","               epochs = 50,\n","               validation_data = test_generator,\n","               validation_steps = 800)"]},{"cell_type":"markdown","source":["**Step 3: Making Predicitons with our Model**"],"metadata":{"id":"CiejyD2P3Rs9"}},{"cell_type":"code","source":["# Load sample image off the web\n","unseen_image = load_img('unseen_image/cat_or_dog.jpg',\n","                              target_size = (128,128))\n","unseen_image = img_to_array(unseen_image)"],"metadata":{"id":"uZrSfT4I3lKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Format image by adding batch_size dimension\n","unseen_image = np.expand_dims(unseen_image, axis = 0)\n","result = classifier.predict(unseen_image)\n","train_generator.class_indices\n","prediction = 'dog' if result[0][0] == 1 else 'cat'\n","print('This is a', prediction, '!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rj7N3sCiQpdf","executionInfo":{"status":"error","timestamp":1681634981729,"user_tz":420,"elapsed":693,"user":{"displayName":"Samuel Boerner","userId":"02136363046085809473"}},"outputId":"9c20e9a4-af81-4abf-d7d9-132f3d16a745"},"execution_count":null,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-e6b6b6fac3d6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Format image by adding batch_size dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0munseen_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munseen_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munseen_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dog'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/conv2d_2/Relu' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-59-e6b6b6fac3d6>\", line 3, in <cell line: 3>\n      result = classifier.predict(unseen_image)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_1/conv2d_2/Relu'\nconvolution input must be 4-dimensional: [1,1,28,28,1]\n\t [[{{node sequential_1/conv2d_2/Relu}}]] [Op:__inference_predict_function_101238]"]}]},{"cell_type":"markdown","source":["# Case Study 2: Handwritten Digit Classifier using MNIST Dataset"],"metadata":{"id":"hDrOypUIGCXY"}},{"cell_type":"markdown","source":["**Step 1: Loading the MNIST Dataset**"],"metadata":{"id":"yX-tc87DOrJc"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.utils import load_img\n","from keras.utils import img_to_array\n","\n","%cd /content/drive/My Drive/2022-23/S23/CS-200/Week 10/mnist/"],"metadata":{"id":"8UuH1ra2GbCE","executionInfo":{"status":"ok","timestamp":1681633873369,"user_tz":420,"elapsed":156,"user":{"displayName":"Samuel Boerner","userId":"02136363046085809473"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fc0c71d-c07d-4bb6-bd25-d13815ce179c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/2022-23/S23/CS-200/Week 10/mnist\n"]}]},{"cell_type":"code","source":["# Load dataset\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8M-lJ-xG8JC","executionInfo":{"status":"ok","timestamp":1681631508408,"user_tz":420,"elapsed":1711,"user":{"displayName":"Samuel Boerner","userId":"02136363046085809473"}},"outputId":"ce771f49-897d-44e5-f1b1-3e9214bc0169"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["**Step 2: Data Preprocessing**"],"metadata":{"id":"F7e00HIrOysX"}},{"cell_type":"code","source":["# Reshaping the array into 4D\n","x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","input_shape = (28, 28, 1)"],"metadata":{"id":"2R4ICoL8HoWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confirm the values are floats\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","# Normalizing the RGB codes by dividing it to the max RGB value\n","x_train /= 255\n","x_test /= 255"],"metadata":{"id":"TlhdFAhQIa89"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 3: Building and Evaluating the Model**"],"metadata":{"id":"h2e8FUsyPHc2"}},{"cell_type":"code","source":["# Initialize CNN\n","classifier = Sequential()\n","\n","# Convolution\n","classifier.add(Conv2D(filters = 32, kernel_size = 3, input_shape = input_shape, activation = 'relu'))\n","\n","# Pooling\n","classifier.add(MaxPooling2D(pool_size = 2, strides = 2))\n","\n","# Flattening\n","classifier.add(Flatten())\n","\n","# Full connection\n","classifier.add(Dense(units = 200, activation = 'relu'))\n","\n","# Dropout layer\n","classifier.add(Dropout(0.5))\n","\n","# Output layer\n","classifier.add(Dense(units = 10, activation = 'softmax'))"],"metadata":{"id":"WTgyZ55AI-VP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compilation\n","classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"],"metadata":{"id":"39f9sFSIJn9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model fitting and evaluation\n","classifier.fit(x = x_train, y = y_train, epochs = 10)\n","classifier.evaluate(x = x_test, y = y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lh8nNEx1J8gq","executionInfo":{"status":"ok","timestamp":1681632027096,"user_tz":420,"elapsed":506330,"user":{"displayName":"Samuel Boerner","userId":"02136363046085809473"}},"outputId":"c60e335d-47cf-4af0-dc78-6a5c1f029680"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1875/1875 [==============================] - 52s 27ms/step - loss: 0.2112 - accuracy: 0.9362\n","Epoch 2/10\n","1875/1875 [==============================] - 51s 27ms/step - loss: 0.0836 - accuracy: 0.9748\n","Epoch 3/10\n","1875/1875 [==============================] - 49s 26ms/step - loss: 0.0621 - accuracy: 0.9812\n","Epoch 4/10\n","1875/1875 [==============================] - 49s 26ms/step - loss: 0.0492 - accuracy: 0.9846\n","Epoch 5/10\n","1875/1875 [==============================] - 49s 26ms/step - loss: 0.0386 - accuracy: 0.9874\n","Epoch 6/10\n","1875/1875 [==============================] - 50s 27ms/step - loss: 0.0344 - accuracy: 0.9885\n","Epoch 7/10\n","1875/1875 [==============================] - 48s 26ms/step - loss: 0.0277 - accuracy: 0.9905\n","Epoch 8/10\n","1875/1875 [==============================] - 48s 26ms/step - loss: 0.0248 - accuracy: 0.9915\n","Epoch 9/10\n","1875/1875 [==============================] - 50s 27ms/step - loss: 0.0225 - accuracy: 0.9923\n","Epoch 10/10\n","1875/1875 [==============================] - 49s 26ms/step - loss: 0.0179 - accuracy: 0.9938\n","313/313 [==============================] - 3s 10ms/step - loss: 0.0386 - accuracy: 0.9897\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.03860843926668167, 0.9897000193595886]"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["**Step 4: Making Predicitons with our Model**"],"metadata":{"id":"HFJCAUQrPnOG"}},{"cell_type":"code","source":["# # Load sample image off the web and make a single prediction\n","unseen_image = load_img('unseen_image/Number-0-handwritten_2_128x128.png', color_mode = 'grayscale', target_size = (28, 28, 1))\n","unseen_image = img_to_array(unseen_image)\n","unseen_image = np.expand_dims(unseen_image, axis = 0)\n","unseen_image = unseen_image.astype('float32')\n","unseen_image = unseen_image/225.0\n","result = classifier.predict(unseen_image)\n","print('This is a', np.argmax(result), '!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVsGRtWoMZni","executionInfo":{"status":"ok","timestamp":1681635217578,"user_tz":420,"elapsed":172,"user":{"displayName":"Samuel Boerner","userId":"02136363046085809473"}},"outputId":"a89bf1f9-9686-402b-cf73-de4841ed8ac7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","This is a 0 !\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQpjgf9hIHsd79mvHYLCeY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}